{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/250\n",
      "48000/48000 [==============================] - 2s - loss: 1.7404 - acc: 0.4540 - val_loss: 0.9292 - val_acc: 0.8124\n",
      "Epoch 2/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.9232 - acc: 0.7230 - val_loss: 0.5400 - val_acc: 0.8652\n",
      "Epoch 3/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.6935 - acc: 0.7882 - val_loss: 0.4298 - val_acc: 0.8885\n",
      "Epoch 4/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.5947 - acc: 0.8210 - val_loss: 0.3790 - val_acc: 0.8976\n",
      "Epoch 5/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.5347 - acc: 0.8394 - val_loss: 0.3456 - val_acc: 0.9040\n",
      "Epoch 6/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.4977 - acc: 0.8525 - val_loss: 0.3232 - val_acc: 0.9107\n",
      "Epoch 7/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.4617 - acc: 0.8629 - val_loss: 0.3048 - val_acc: 0.9128\n",
      "Epoch 8/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.4386 - acc: 0.8689 - val_loss: 0.2896 - val_acc: 0.9172\n",
      "Epoch 9/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.4181 - acc: 0.8760 - val_loss: 0.2776 - val_acc: 0.9198\n",
      "Epoch 10/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.3990 - acc: 0.8837 - val_loss: 0.2656 - val_acc: 0.9233\n",
      "Epoch 11/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.3819 - acc: 0.8876 - val_loss: 0.2551 - val_acc: 0.9257\n",
      "Epoch 12/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.3688 - acc: 0.8920 - val_loss: 0.2465 - val_acc: 0.9283\n",
      "Epoch 13/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.3571 - acc: 0.8942 - val_loss: 0.2388 - val_acc: 0.9300\n",
      "Epoch 14/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.3466 - acc: 0.8992 - val_loss: 0.2319 - val_acc: 0.9322\n",
      "Epoch 15/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.3359 - acc: 0.9015 - val_loss: 0.2261 - val_acc: 0.9339\n",
      "Epoch 16/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.3244 - acc: 0.9055 - val_loss: 0.2180 - val_acc: 0.9352\n",
      "Epoch 17/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.3142 - acc: 0.9086 - val_loss: 0.2122 - val_acc: 0.9377\n",
      "Epoch 18/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.3103 - acc: 0.9095 - val_loss: 0.2076 - val_acc: 0.9389\n",
      "Epoch 19/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.3019 - acc: 0.9117 - val_loss: 0.2019 - val_acc: 0.9409\n",
      "Epoch 20/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.2931 - acc: 0.9131 - val_loss: 0.1974 - val_acc: 0.9419\n",
      "Epoch 21/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.2866 - acc: 0.9171 - val_loss: 0.1920 - val_acc: 0.9438\n",
      "Epoch 22/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.2789 - acc: 0.9171 - val_loss: 0.1879 - val_acc: 0.9447\n",
      "Epoch 23/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.2730 - acc: 0.9200 - val_loss: 0.1842 - val_acc: 0.9463\n",
      "Epoch 24/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.2686 - acc: 0.9212 - val_loss: 0.1811 - val_acc: 0.9465\n",
      "Epoch 25/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.2618 - acc: 0.9234 - val_loss: 0.1770 - val_acc: 0.9479\n",
      "Epoch 26/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.2584 - acc: 0.9249 - val_loss: 0.1735 - val_acc: 0.9488\n",
      "Epoch 27/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.2539 - acc: 0.9254 - val_loss: 0.1706 - val_acc: 0.9496\n",
      "Epoch 28/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.2453 - acc: 0.9277 - val_loss: 0.1677 - val_acc: 0.9502\n",
      "Epoch 29/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.2427 - acc: 0.9275 - val_loss: 0.1641 - val_acc: 0.9517\n",
      "Epoch 30/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.2397 - acc: 0.9298 - val_loss: 0.1615 - val_acc: 0.9522\n",
      "Epoch 31/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.2361 - acc: 0.9304 - val_loss: 0.1590 - val_acc: 0.9533\n",
      "Epoch 32/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.2320 - acc: 0.9307 - val_loss: 0.1568 - val_acc: 0.9544\n",
      "Epoch 33/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.2284 - acc: 0.9326 - val_loss: 0.1534 - val_acc: 0.9553\n",
      "Epoch 34/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.2257 - acc: 0.9328 - val_loss: 0.1519 - val_acc: 0.9552\n",
      "Epoch 35/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.2214 - acc: 0.9354 - val_loss: 0.1501 - val_acc: 0.9556\n",
      "Epoch 36/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.2169 - acc: 0.9354 - val_loss: 0.1485 - val_acc: 0.9565\n",
      "Epoch 37/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.2124 - acc: 0.9376 - val_loss: 0.1459 - val_acc: 0.9572\n",
      "Epoch 38/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.2122 - acc: 0.9372 - val_loss: 0.1432 - val_acc: 0.9579\n",
      "Epoch 39/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.2091 - acc: 0.9387 - val_loss: 0.1422 - val_acc: 0.9576\n",
      "Epoch 40/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.2042 - acc: 0.9393 - val_loss: 0.1410 - val_acc: 0.9581\n",
      "Epoch 41/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.2027 - acc: 0.9397 - val_loss: 0.1396 - val_acc: 0.9583\n",
      "Epoch 42/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1985 - acc: 0.9415 - val_loss: 0.1367 - val_acc: 0.9594\n",
      "Epoch 43/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.2003 - acc: 0.9409 - val_loss: 0.1350 - val_acc: 0.9608\n",
      "Epoch 44/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.1953 - acc: 0.9423 - val_loss: 0.1337 - val_acc: 0.9606\n",
      "Epoch 45/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1920 - acc: 0.9431 - val_loss: 0.1332 - val_acc: 0.9599\n",
      "Epoch 46/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.1901 - acc: 0.9444 - val_loss: 0.1316 - val_acc: 0.9616\n",
      "Epoch 47/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1876 - acc: 0.9449 - val_loss: 0.1299 - val_acc: 0.9611\n",
      "Epoch 48/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.1866 - acc: 0.9443 - val_loss: 0.1300 - val_acc: 0.9617\n",
      "Epoch 49/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1865 - acc: 0.9453 - val_loss: 0.1282 - val_acc: 0.9615\n",
      "Epoch 50/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1803 - acc: 0.9462 - val_loss: 0.1267 - val_acc: 0.9623\n",
      "Epoch 51/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1822 - acc: 0.9466 - val_loss: 0.1254 - val_acc: 0.9631\n",
      "Epoch 52/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1794 - acc: 0.9460 - val_loss: 0.1244 - val_acc: 0.9632\n",
      "Epoch 53/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 1s - loss: 0.1752 - acc: 0.9479 - val_loss: 0.1234 - val_acc: 0.9633\n",
      "Epoch 54/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1738 - acc: 0.9477 - val_loss: 0.1220 - val_acc: 0.9637\n",
      "Epoch 55/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.1736 - acc: 0.9493 - val_loss: 0.1209 - val_acc: 0.9645\n",
      "Epoch 56/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.1719 - acc: 0.9486 - val_loss: 0.1207 - val_acc: 0.9639\n",
      "Epoch 57/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1692 - acc: 0.9504 - val_loss: 0.1189 - val_acc: 0.9650\n",
      "Epoch 58/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1663 - acc: 0.9508 - val_loss: 0.1187 - val_acc: 0.9651\n",
      "Epoch 59/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1682 - acc: 0.9500 - val_loss: 0.1172 - val_acc: 0.9654\n",
      "Epoch 60/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.1647 - acc: 0.9515 - val_loss: 0.1165 - val_acc: 0.9652\n",
      "Epoch 61/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1614 - acc: 0.9524 - val_loss: 0.1157 - val_acc: 0.9657\n",
      "Epoch 62/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1592 - acc: 0.9527 - val_loss: 0.1149 - val_acc: 0.9657\n",
      "Epoch 63/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.1587 - acc: 0.9533 - val_loss: 0.1142 - val_acc: 0.9657\n",
      "Epoch 64/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.1564 - acc: 0.9530 - val_loss: 0.1126 - val_acc: 0.9667\n",
      "Epoch 65/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1560 - acc: 0.9539 - val_loss: 0.1128 - val_acc: 0.9667\n",
      "Epoch 66/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.1572 - acc: 0.9534 - val_loss: 0.1120 - val_acc: 0.9663\n",
      "Epoch 67/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1553 - acc: 0.9547 - val_loss: 0.1106 - val_acc: 0.9668\n",
      "Epoch 68/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1525 - acc: 0.9544 - val_loss: 0.1102 - val_acc: 0.9672\n",
      "Epoch 69/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1523 - acc: 0.9554 - val_loss: 0.1089 - val_acc: 0.9676\n",
      "Epoch 70/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1502 - acc: 0.9552 - val_loss: 0.1086 - val_acc: 0.9678\n",
      "Epoch 71/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1478 - acc: 0.9567 - val_loss: 0.1082 - val_acc: 0.9682\n",
      "Epoch 72/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1450 - acc: 0.9566 - val_loss: 0.1073 - val_acc: 0.9685\n",
      "Epoch 73/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1462 - acc: 0.9568 - val_loss: 0.1068 - val_acc: 0.9680\n",
      "Epoch 74/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1439 - acc: 0.9582 - val_loss: 0.1067 - val_acc: 0.9682\n",
      "Epoch 75/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1447 - acc: 0.9566 - val_loss: 0.1059 - val_acc: 0.9682\n",
      "Epoch 76/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1414 - acc: 0.9579 - val_loss: 0.1059 - val_acc: 0.9684\n",
      "Epoch 77/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.1421 - acc: 0.9580 - val_loss: 0.1055 - val_acc: 0.9681\n",
      "Epoch 78/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1399 - acc: 0.9586 - val_loss: 0.1044 - val_acc: 0.9691\n",
      "Epoch 79/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1415 - acc: 0.9572 - val_loss: 0.1041 - val_acc: 0.9687\n",
      "Epoch 80/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1393 - acc: 0.9594 - val_loss: 0.1033 - val_acc: 0.9689\n",
      "Epoch 81/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1370 - acc: 0.9592 - val_loss: 0.1036 - val_acc: 0.9687\n",
      "Epoch 82/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1365 - acc: 0.9579 - val_loss: 0.1031 - val_acc: 0.9687\n",
      "Epoch 83/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1344 - acc: 0.9597 - val_loss: 0.1020 - val_acc: 0.9692\n",
      "Epoch 84/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1338 - acc: 0.9600 - val_loss: 0.1015 - val_acc: 0.9692\n",
      "Epoch 85/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1337 - acc: 0.9604 - val_loss: 0.1014 - val_acc: 0.9697\n",
      "Epoch 86/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.1346 - acc: 0.9601 - val_loss: 0.1005 - val_acc: 0.9700\n",
      "Epoch 87/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1304 - acc: 0.9607 - val_loss: 0.1003 - val_acc: 0.9706\n",
      "Epoch 88/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.1321 - acc: 0.9596 - val_loss: 0.1000 - val_acc: 0.9697\n",
      "Epoch 89/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1304 - acc: 0.9607 - val_loss: 0.0991 - val_acc: 0.9702\n",
      "Epoch 90/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.1321 - acc: 0.9604 - val_loss: 0.0987 - val_acc: 0.9704\n",
      "Epoch 91/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1286 - acc: 0.9621 - val_loss: 0.0982 - val_acc: 0.9710\n",
      "Epoch 92/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1317 - acc: 0.9601 - val_loss: 0.0986 - val_acc: 0.9714\n",
      "Epoch 93/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1285 - acc: 0.9614 - val_loss: 0.0977 - val_acc: 0.9712\n",
      "Epoch 94/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1249 - acc: 0.9622 - val_loss: 0.0974 - val_acc: 0.9710\n",
      "Epoch 95/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1265 - acc: 0.9629 - val_loss: 0.0974 - val_acc: 0.9712\n",
      "Epoch 96/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1239 - acc: 0.9625 - val_loss: 0.0969 - val_acc: 0.9717\n",
      "Epoch 97/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1241 - acc: 0.9622 - val_loss: 0.0960 - val_acc: 0.9712\n",
      "Epoch 98/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1235 - acc: 0.9631 - val_loss: 0.0965 - val_acc: 0.9716\n",
      "Epoch 99/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1216 - acc: 0.9644 - val_loss: 0.0957 - val_acc: 0.9716\n",
      "Epoch 100/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1211 - acc: 0.9636 - val_loss: 0.0957 - val_acc: 0.9720\n",
      "Epoch 101/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1227 - acc: 0.9631 - val_loss: 0.0961 - val_acc: 0.9722\n",
      "Epoch 102/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1214 - acc: 0.9642 - val_loss: 0.0947 - val_acc: 0.9724\n",
      "Epoch 103/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.1192 - acc: 0.9646 - val_loss: 0.0950 - val_acc: 0.9720\n",
      "Epoch 104/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1177 - acc: 0.9649 - val_loss: 0.0942 - val_acc: 0.9721\n",
      "Epoch 105/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1164 - acc: 0.9656 - val_loss: 0.0943 - val_acc: 0.9727\n",
      "Epoch 106/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1170 - acc: 0.9650 - val_loss: 0.0940 - val_acc: 0.9726\n",
      "Epoch 107/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1169 - acc: 0.9647 - val_loss: 0.0940 - val_acc: 0.9731\n",
      "Epoch 108/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1138 - acc: 0.9666 - val_loss: 0.0933 - val_acc: 0.9725\n",
      "Epoch 109/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1146 - acc: 0.9659 - val_loss: 0.0933 - val_acc: 0.9733\n",
      "Epoch 110/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1140 - acc: 0.9659 - val_loss: 0.0928 - val_acc: 0.9729\n",
      "Epoch 111/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.1147 - acc: 0.9659 - val_loss: 0.0927 - val_acc: 0.9721\n",
      "Epoch 112/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1116 - acc: 0.9662 - val_loss: 0.0917 - val_acc: 0.9740\n",
      "Epoch 113/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1127 - acc: 0.9657 - val_loss: 0.0921 - val_acc: 0.9732\n",
      "Epoch 114/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1144 - acc: 0.9655 - val_loss: 0.0915 - val_acc: 0.9737\n",
      "Epoch 115/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1113 - acc: 0.9663 - val_loss: 0.0914 - val_acc: 0.9740\n",
      "Epoch 116/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 1s - loss: 0.1087 - acc: 0.9672 - val_loss: 0.0911 - val_acc: 0.9737\n",
      "Epoch 117/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1115 - acc: 0.9664 - val_loss: 0.0912 - val_acc: 0.9734\n",
      "Epoch 118/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1086 - acc: 0.9671 - val_loss: 0.0907 - val_acc: 0.9737\n",
      "Epoch 119/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1117 - acc: 0.9660 - val_loss: 0.0910 - val_acc: 0.9739\n",
      "Epoch 120/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1070 - acc: 0.9677 - val_loss: 0.0901 - val_acc: 0.9743\n",
      "Epoch 121/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1084 - acc: 0.9669 - val_loss: 0.0904 - val_acc: 0.9743\n",
      "Epoch 122/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1074 - acc: 0.9673 - val_loss: 0.0895 - val_acc: 0.9746\n",
      "Epoch 123/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.1043 - acc: 0.9680 - val_loss: 0.0891 - val_acc: 0.9745\n",
      "Epoch 124/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.1046 - acc: 0.9684 - val_loss: 0.0894 - val_acc: 0.9745\n",
      "Epoch 125/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1043 - acc: 0.9691 - val_loss: 0.0892 - val_acc: 0.9742\n",
      "Epoch 126/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1035 - acc: 0.9686 - val_loss: 0.0888 - val_acc: 0.9747\n",
      "Epoch 127/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1033 - acc: 0.9685 - val_loss: 0.0889 - val_acc: 0.9745\n",
      "Epoch 128/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1042 - acc: 0.9687 - val_loss: 0.0884 - val_acc: 0.9751\n",
      "Epoch 129/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1051 - acc: 0.9675 - val_loss: 0.0883 - val_acc: 0.9755\n",
      "Epoch 130/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1040 - acc: 0.9690 - val_loss: 0.0883 - val_acc: 0.9752\n",
      "Epoch 131/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1025 - acc: 0.9686 - val_loss: 0.0876 - val_acc: 0.9751\n",
      "Epoch 132/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0998 - acc: 0.9703 - val_loss: 0.0879 - val_acc: 0.9751\n",
      "Epoch 133/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1009 - acc: 0.9688 - val_loss: 0.0876 - val_acc: 0.9748\n",
      "Epoch 134/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0989 - acc: 0.9686 - val_loss: 0.0877 - val_acc: 0.9750\n",
      "Epoch 135/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1007 - acc: 0.9692 - val_loss: 0.0879 - val_acc: 0.9748\n",
      "Epoch 136/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1000 - acc: 0.9704 - val_loss: 0.0876 - val_acc: 0.9751\n",
      "Epoch 137/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0996 - acc: 0.9695 - val_loss: 0.0878 - val_acc: 0.9754\n",
      "Epoch 138/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.1003 - acc: 0.9690 - val_loss: 0.0874 - val_acc: 0.9754\n",
      "Epoch 139/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0975 - acc: 0.9706 - val_loss: 0.0873 - val_acc: 0.9754\n",
      "Epoch 140/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0964 - acc: 0.9708 - val_loss: 0.0869 - val_acc: 0.9757\n",
      "Epoch 141/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0971 - acc: 0.9699 - val_loss: 0.0868 - val_acc: 0.9759\n",
      "Epoch 142/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0952 - acc: 0.9709 - val_loss: 0.0864 - val_acc: 0.9761\n",
      "Epoch 143/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.0969 - acc: 0.9702 - val_loss: 0.0868 - val_acc: 0.9761\n",
      "Epoch 144/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0946 - acc: 0.9711 - val_loss: 0.0865 - val_acc: 0.9758\n",
      "Epoch 145/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0961 - acc: 0.9708 - val_loss: 0.0859 - val_acc: 0.9761\n",
      "Epoch 146/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0939 - acc: 0.9720 - val_loss: 0.0863 - val_acc: 0.9756\n",
      "Epoch 147/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0936 - acc: 0.9715 - val_loss: 0.0865 - val_acc: 0.9761\n",
      "Epoch 148/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0948 - acc: 0.9710 - val_loss: 0.0861 - val_acc: 0.9759\n",
      "Epoch 149/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0925 - acc: 0.9720 - val_loss: 0.0856 - val_acc: 0.9757\n",
      "Epoch 150/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0917 - acc: 0.9721 - val_loss: 0.0862 - val_acc: 0.9760\n",
      "Epoch 151/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0941 - acc: 0.9718 - val_loss: 0.0856 - val_acc: 0.9760\n",
      "Epoch 152/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0923 - acc: 0.9723 - val_loss: 0.0852 - val_acc: 0.9765\n",
      "Epoch 153/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.0892 - acc: 0.9727 - val_loss: 0.0852 - val_acc: 0.9758\n",
      "Epoch 154/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0916 - acc: 0.9724 - val_loss: 0.0854 - val_acc: 0.9761\n",
      "Epoch 155/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0909 - acc: 0.9726 - val_loss: 0.0850 - val_acc: 0.9761\n",
      "Epoch 156/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0910 - acc: 0.9726 - val_loss: 0.0848 - val_acc: 0.9758\n",
      "Epoch 157/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0901 - acc: 0.9730 - val_loss: 0.0849 - val_acc: 0.9762\n",
      "Epoch 158/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0885 - acc: 0.9730 - val_loss: 0.0854 - val_acc: 0.9758\n",
      "Epoch 159/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0878 - acc: 0.9727 - val_loss: 0.0845 - val_acc: 0.9767\n",
      "Epoch 160/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0893 - acc: 0.9729 - val_loss: 0.0849 - val_acc: 0.9762\n",
      "Epoch 161/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0887 - acc: 0.9728 - val_loss: 0.0842 - val_acc: 0.9765\n",
      "Epoch 162/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0885 - acc: 0.9734 - val_loss: 0.0842 - val_acc: 0.9762\n",
      "Epoch 163/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0870 - acc: 0.9733 - val_loss: 0.0846 - val_acc: 0.9763\n",
      "Epoch 164/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0878 - acc: 0.9730 - val_loss: 0.0841 - val_acc: 0.9768\n",
      "Epoch 165/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0860 - acc: 0.9735 - val_loss: 0.0839 - val_acc: 0.9762\n",
      "Epoch 166/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0863 - acc: 0.9731 - val_loss: 0.0848 - val_acc: 0.9761\n",
      "Epoch 167/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0857 - acc: 0.9736 - val_loss: 0.0846 - val_acc: 0.9759\n",
      "Epoch 168/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0837 - acc: 0.9747 - val_loss: 0.0843 - val_acc: 0.9762\n",
      "Epoch 169/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0853 - acc: 0.9741 - val_loss: 0.0839 - val_acc: 0.9759\n",
      "Epoch 170/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0872 - acc: 0.9735 - val_loss: 0.0833 - val_acc: 0.9762\n",
      "Epoch 171/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0854 - acc: 0.9739 - val_loss: 0.0832 - val_acc: 0.9767\n",
      "Epoch 172/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0845 - acc: 0.9736 - val_loss: 0.0833 - val_acc: 0.9761\n",
      "Epoch 173/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0858 - acc: 0.9740 - val_loss: 0.0839 - val_acc: 0.9763\n",
      "Epoch 174/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.0826 - acc: 0.9747 - val_loss: 0.0832 - val_acc: 0.9765\n",
      "Epoch 175/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0857 - acc: 0.9734 - val_loss: 0.0836 - val_acc: 0.9765\n",
      "Epoch 176/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0807 - acc: 0.9753 - val_loss: 0.0837 - val_acc: 0.9766\n",
      "Epoch 177/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0823 - acc: 0.9750 - val_loss: 0.0828 - val_acc: 0.9770\n",
      "Epoch 178/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0825 - acc: 0.9746 - val_loss: 0.0827 - val_acc: 0.9771\n",
      "Epoch 179/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 1s - loss: 0.0812 - acc: 0.9752 - val_loss: 0.0822 - val_acc: 0.9764\n",
      "Epoch 180/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0834 - acc: 0.9740 - val_loss: 0.0831 - val_acc: 0.9766\n",
      "Epoch 181/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0812 - acc: 0.9747 - val_loss: 0.0818 - val_acc: 0.9768\n",
      "Epoch 182/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0784 - acc: 0.9758 - val_loss: 0.0826 - val_acc: 0.9769\n",
      "Epoch 183/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0802 - acc: 0.9759 - val_loss: 0.0824 - val_acc: 0.9768\n",
      "Epoch 184/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0808 - acc: 0.9750 - val_loss: 0.0818 - val_acc: 0.9765\n",
      "Epoch 185/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0792 - acc: 0.9755 - val_loss: 0.0822 - val_acc: 0.9764\n",
      "Epoch 186/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0806 - acc: 0.9755 - val_loss: 0.0825 - val_acc: 0.9768\n",
      "Epoch 187/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0785 - acc: 0.9758 - val_loss: 0.0821 - val_acc: 0.9764\n",
      "Epoch 188/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0795 - acc: 0.9752 - val_loss: 0.0813 - val_acc: 0.9767\n",
      "Epoch 189/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0775 - acc: 0.9759 - val_loss: 0.0821 - val_acc: 0.9767\n",
      "Epoch 190/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0775 - acc: 0.9759 - val_loss: 0.0821 - val_acc: 0.9761\n",
      "Epoch 191/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0780 - acc: 0.9767 - val_loss: 0.0822 - val_acc: 0.9766\n",
      "Epoch 192/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0797 - acc: 0.9757 - val_loss: 0.0821 - val_acc: 0.9771\n",
      "Epoch 193/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0775 - acc: 0.9762 - val_loss: 0.0818 - val_acc: 0.9770\n",
      "Epoch 194/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0780 - acc: 0.9761 - val_loss: 0.0818 - val_acc: 0.9769\n",
      "Epoch 195/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0768 - acc: 0.9764 - val_loss: 0.0820 - val_acc: 0.9763\n",
      "Epoch 196/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0742 - acc: 0.9770 - val_loss: 0.0817 - val_acc: 0.9766\n",
      "Epoch 197/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0769 - acc: 0.9756 - val_loss: 0.0816 - val_acc: 0.9767\n",
      "Epoch 198/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0749 - acc: 0.9769 - val_loss: 0.0814 - val_acc: 0.9768\n",
      "Epoch 199/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0750 - acc: 0.9771 - val_loss: 0.0811 - val_acc: 0.9769\n",
      "Epoch 200/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0743 - acc: 0.9768 - val_loss: 0.0810 - val_acc: 0.9762\n",
      "Epoch 201/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0746 - acc: 0.9764 - val_loss: 0.0815 - val_acc: 0.9768\n",
      "Epoch 202/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0781 - acc: 0.9762 - val_loss: 0.0811 - val_acc: 0.9771\n",
      "Epoch 203/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0748 - acc: 0.9771 - val_loss: 0.0811 - val_acc: 0.9768\n",
      "Epoch 204/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0719 - acc: 0.9774 - val_loss: 0.0810 - val_acc: 0.9769\n",
      "Epoch 205/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0753 - acc: 0.9768 - val_loss: 0.0814 - val_acc: 0.9768\n",
      "Epoch 206/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0731 - acc: 0.9774 - val_loss: 0.0812 - val_acc: 0.9771\n",
      "Epoch 207/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0724 - acc: 0.9775 - val_loss: 0.0811 - val_acc: 0.9762\n",
      "Epoch 208/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0726 - acc: 0.9771 - val_loss: 0.0814 - val_acc: 0.9769\n",
      "Epoch 209/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0731 - acc: 0.9775 - val_loss: 0.0813 - val_acc: 0.9769\n",
      "Epoch 210/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0710 - acc: 0.9778 - val_loss: 0.0815 - val_acc: 0.9768\n",
      "Epoch 211/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0734 - acc: 0.9766 - val_loss: 0.0819 - val_acc: 0.9772\n",
      "Epoch 212/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0738 - acc: 0.9770 - val_loss: 0.0815 - val_acc: 0.9766\n",
      "Epoch 213/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0724 - acc: 0.9778 - val_loss: 0.0809 - val_acc: 0.9776\n",
      "Epoch 214/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0722 - acc: 0.9779 - val_loss: 0.0810 - val_acc: 0.9773\n",
      "Epoch 215/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0705 - acc: 0.9785 - val_loss: 0.0808 - val_acc: 0.9772\n",
      "Epoch 216/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0707 - acc: 0.9775 - val_loss: 0.0808 - val_acc: 0.9770\n",
      "Epoch 217/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0707 - acc: 0.9784 - val_loss: 0.0806 - val_acc: 0.9772\n",
      "Epoch 218/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0687 - acc: 0.9786 - val_loss: 0.0810 - val_acc: 0.9768\n",
      "Epoch 219/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0706 - acc: 0.9780 - val_loss: 0.0802 - val_acc: 0.9769\n",
      "Epoch 220/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0689 - acc: 0.9789 - val_loss: 0.0803 - val_acc: 0.9768\n",
      "Epoch 221/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0705 - acc: 0.9779 - val_loss: 0.0811 - val_acc: 0.9767\n",
      "Epoch 222/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0687 - acc: 0.9788 - val_loss: 0.0808 - val_acc: 0.9768\n",
      "Epoch 223/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.0707 - acc: 0.9773 - val_loss: 0.0807 - val_acc: 0.9770\n",
      "Epoch 224/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.0699 - acc: 0.9791 - val_loss: 0.0804 - val_acc: 0.9772\n",
      "Epoch 225/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0674 - acc: 0.9787 - val_loss: 0.0807 - val_acc: 0.9776\n",
      "Epoch 226/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0684 - acc: 0.9787 - val_loss: 0.0805 - val_acc: 0.9770\n",
      "Epoch 227/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0668 - acc: 0.9793 - val_loss: 0.0807 - val_acc: 0.9771\n",
      "Epoch 228/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0693 - acc: 0.9786 - val_loss: 0.0807 - val_acc: 0.9771\n",
      "Epoch 229/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0688 - acc: 0.9784 - val_loss: 0.0807 - val_acc: 0.9769\n",
      "Epoch 230/250\n",
      "48000/48000 [==============================] - 2s - loss: 0.0684 - acc: 0.9788 - val_loss: 0.0801 - val_acc: 0.9769\n",
      "Epoch 231/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0671 - acc: 0.9793 - val_loss: 0.0799 - val_acc: 0.9774\n",
      "Epoch 232/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0681 - acc: 0.9787 - val_loss: 0.0801 - val_acc: 0.9772\n",
      "Epoch 233/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0647 - acc: 0.9796 - val_loss: 0.0806 - val_acc: 0.9775\n",
      "Epoch 234/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0678 - acc: 0.9784 - val_loss: 0.0803 - val_acc: 0.9776\n",
      "Epoch 235/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0663 - acc: 0.9792 - val_loss: 0.0795 - val_acc: 0.9775\n",
      "Epoch 236/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0687 - acc: 0.9785 - val_loss: 0.0795 - val_acc: 0.9776\n",
      "Epoch 237/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0650 - acc: 0.9795 - val_loss: 0.0801 - val_acc: 0.9776\n",
      "Epoch 238/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0664 - acc: 0.9793 - val_loss: 0.0805 - val_acc: 0.9774\n",
      "Epoch 239/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0669 - acc: 0.9793 - val_loss: 0.0807 - val_acc: 0.9776\n",
      "Epoch 240/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0688 - acc: 0.9784 - val_loss: 0.0802 - val_acc: 0.9776\n",
      "Epoch 241/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0648 - acc: 0.9798 - val_loss: 0.0806 - val_acc: 0.9772\n",
      "Epoch 242/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 1s - loss: 0.0657 - acc: 0.9792 - val_loss: 0.0798 - val_acc: 0.9775\n",
      "Epoch 243/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0658 - acc: 0.9791 - val_loss: 0.0796 - val_acc: 0.9778\n",
      "Epoch 244/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0655 - acc: 0.9796 - val_loss: 0.0798 - val_acc: 0.9773\n",
      "Epoch 245/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0634 - acc: 0.9804 - val_loss: 0.0799 - val_acc: 0.9775\n",
      "Epoch 246/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0629 - acc: 0.9803 - val_loss: 0.0810 - val_acc: 0.9770\n",
      "Epoch 247/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0620 - acc: 0.9804 - val_loss: 0.0801 - val_acc: 0.9775\n",
      "Epoch 248/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0632 - acc: 0.9803 - val_loss: 0.0802 - val_acc: 0.9770\n",
      "Epoch 249/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0635 - acc: 0.9800 - val_loss: 0.0804 - val_acc: 0.9777\n",
      "Epoch 250/250\n",
      "48000/48000 [==============================] - 1s - loss: 0.0616 - acc: 0.9809 - val_loss: 0.0801 - val_acc: 0.9775\n",
      " 9216/10000 [==========================>...] - ETA: 0s\n",
      "Test score: 0.077391580329\n",
      "Test accuracy: 0.9777\n",
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0888c8c908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcXWWd5/HP7661prJUJSGbCRAwASFAiIKgIIIJKogw\nNCi0Y6uRGe1lppsRp93anp52tNvxRYsCal5oq6DDonQbFFC2ljWJLGEJCTGQqpBUpbLUXnf7zR/n\nVHJTqVu5leTUTaq+79frvu65Z7n3ObnJ/eZ5nvM8x9wdERGRA4lVugAiInJ0UGCIiEhZFBgiIlIW\nBYaIiJRFgSEiImVRYIiISFkUGCKHgZndZmb/q8x9N5nZew/1fURGmwJDRETKosAQEZGyKDBk3Aib\ngq43s+fNrNvMfmBm08zsPjPrNLMHzWxS0f6XmNmLZrbLzB42swVF204zszXhcT8DqgZ91gfM7Nnw\n2MfN7JSDLPOnzGyDme0ws3vNbEa43szs/5pZq5l1mNkLZnZyuO1iM3spLFuLmf3NQf2BiQyiwJDx\n5nLgQuAE4IPAfcD/BJoI/j38BYCZnQDcDvxVuG0l8G9mljKzFPAL4F+BycD/C9+X8NjTgBXAp4Ep\nwC3AvWaWHklBzew9wD8CVwLHAK8Dd4SbLwLeFZ5HQ7hPe7jtB8Cn3b0eOBn43Ug+V6QUBYaMN//i\n7tvcvQV4DHjK3f/g7n3APcBp4X5/AvzK3R9w9yzwT0A1cDbwDiAJfMvds+5+J/BM0WcsB25x96fc\nPe/uPwT6w+NG4qPACndf4+79wOeBs8xsLpAF6oG3AubuL7v7m+FxWWChmU1w953uvmaEnysyJAWG\njDfbipZ7h3hdFy7PIPgfPQDuXgA2AzPDbS2+78ydrxctvwX467A5apeZ7QJmh8eNxOAydBHUIma6\n+++AbwM3Aa1mdquZTQh3vRy4GHjdzB4xs7NG+LkiQ1JgiAxtC8EPPxD0GRD86LcAbwIzw3UD5hQt\nbwb+wd0nFj1q3P32QyxDLUETVwuAu9/o7mcACwmapq4P1z/j7pcCUwmazn4+ws8VGZICQ2RoPwfe\nb2YXmFkS+GuCZqXHgSeAHPAXZpY0sw8DS4qO/R5wnZm9PeycrjWz95tZ/QjLcDvwcTNbFPZ//G+C\nJrRNZnZm+P5JoBvoAwphH8tHzawhbErrAAqH8OcgsocCQ2QI7r4OuAb4F2A7QQf5B9094+4Z4MPA\nfwZ2EPR33F107CrgUwRNRjuBDeG+Iy3Dg8AXgbsIajXHAVeFmycQBNNOgmarduAb4bZrgU1m1gFc\nR9AXInLITDdQEhGRcqiGISIiZVFgiIhIWRQYIiJSFgWGiIiUJVHpAhxOjY2NPnfu3EoXQ0TkqLF6\n9ert7t5Uzr5jKjDmzp3LqlWrKl0MEZGjhpm9fuC9AmqSEhGRsigwRESkLAoMEREpy5jqwxhKNpul\nubmZvr6+ShclUlVVVcyaNYtkMlnpoojIGBVZYJjZCuADQKu7nzzE9uvZO8dNAlgANLn7DjPbBHQC\neSDn7osPthzNzc3U19czd+5c9p1cdOxwd9rb22lubmbevHmVLo6IjFFRNkndBiwttdHdv+Hui9x9\nEcGNYR5x9x1Fu5wfbj/osADo6+tjypQpYzYsAMyMKVOmjPlalIhUVmSB4e6PEszkWY6rCaZyjsRY\nDosB4+EcRaSyKt7pbWY1BDWRu4pWO/Cgma02s+UHOH65ma0ys1VtbW0HVYZtHX109mUP6lgRkfGi\n4oFBcJ+B3w9qjjonbKpaBnzGzN5V6mB3v9XdF7v74qamsgYr7qets5+uvtxBHXsgu3bt4jvf+c6I\nj7v44ovZtWtXBCUSETk4R0JgXMWg5ih3H7gFZStwD/vezeywM4IqTRRKBUYuN3xArVy5kokTJ0ZU\nKhGRkatoYJhZA/Bu4JdF62oHbmUZ3sP4ImBttAWJLjBuuOEGXnvtNRYtWsSZZ57JueeeyyWXXMLC\nhQsB+NCHPsQZZ5zBSSedxK233rrnuLlz57J9+3Y2bdrEggUL+NSnPsVJJ53ERRddRG9vb0SlFREp\nLcrLam8HzgMazawZ+DKQBHD3m8PdLgPud/fuokOnAfeEnbgJ4Kfu/uvDUaa/+7cXeWlLx37rezJ5\nEjEjlRh5fi6cMYEvf/Ckktu/9rWvsXbtWp599lkefvhh3v/+97N27do9l7+uWLGCyZMn09vby5ln\nnsnll1/OlClT9nmP9evXc/vtt/O9732PK6+8krvuuotrrrlmxGUVETkUkQWGu19dxj63EVx+W7xu\nI3BqNKUapiyj9DlLlizZZ6zEjTfeyD333APA5s2bWb9+/X6BMW/ePBYtWgTAGWecwaZNm0aptCIi\ne435kd7FStUEXn6zg/p0glmTayIvQ21t7Z7lhx9+mAcffJAnnniCmpoazjvvvCHHUqTT6T3L8Xhc\nTVIiUhFHQqd3xUXZ6V1fX09nZ+eQ23bv3s2kSZOoqanhlVde4cknn4yoFCIih25c1TBKinDM25Qp\nU3jnO9/JySefTHV1NdOmTduzbenSpdx8880sWLCAE088kXe84x3RFURE5BCZ+2i13kdv8eLFPvgG\nSi+//DILFiwY9rh1WzuoTiaYMyX6JqkolXOuIiLFzGx1uVMwqUkKAMNHrdtbROTopMAANA2TiMiB\nKTBCY6hlTkQkEgoMIu3zFhEZMxQYBE1SqmCIiAxPgQGAMZauFhMRiYICg2ibpA52enOAb33rW/T0\n9BzmEomIHBwFBkQ6W60CQ0TGCo30JpwaJKLEKJ7e/MILL2Tq1Kn8/Oc/p7+/n8suu4y/+7u/o7u7\nmyuvvJLm5mby+Txf/OIX2bZtG1u2bOH888+nsbGRhx56KJoCioiUaXwFxn03wNYX9lt9TDYfLCTj\nI3/P6W+DZV8rubl4evP777+fO++8k6effhp355JLLuHRRx+lra2NGTNm8Ktf/QoI5phqaGjgm9/8\nJg899BCNjY0jL5eIyGGmJqk9ou/0vv/++7n//vs57bTTOP3003nllVdYv349b3vb23jggQf43Oc+\nx2OPPUZDQ0PkZRERGanxVcMoURPYtr2bbL7A/Gn1kX68u/P5z3+eT3/60/ttW7NmDStXruQLX/gC\nF1xwAV/60pciLYuIyEiphhEajenN3/e+97FixQq6uroAaGlpobW1lS1btlBTU8M111zD9ddfz5o1\na/Y7VkSk0sZXDaOEKOeSKp7efNmyZXzkIx/hrLPOAqCuro4f//jHbNiwgeuvv55YLEYymeS73/0u\nAMuXL2fp0qXMmDFDnd4iUnGa3hx4vb2bvmyBE6dH2yQVNU1vLiIjpenNR8g0m5SIyAFFFhhmtsLM\nWs1sbYnt55nZbjN7Nnx8qWjbUjNbZ2YbzOyGqMq49/PQ/TBERA4gyhrGbcDSA+zzmLsvCh9fBTCz\nOHATsAxYCFxtZgsPpSBlNbsd5XkxlpoWReTIFFlguPujwI6DOHQJsMHdN7p7BrgDuPRgy1FVVUV7\ne/uwP6jG0Z0X7k57eztVVVWVLoqIjGGVvkrqbDN7HmgB/sbdXwRmApuL9mkG3n6wHzBr1iyam5tp\na2sruc/Ongx92QLsOnp/cKuqqpg1a1aliyEiY1glA2MNMMfdu8zsYuAXwPyRvomZLQeWA8yZM2e/\n7clkknnz5g37Hl/4xQvc90Irq7944Ug/XkRk3KjYVVLu3uHuXeHySiBpZo0EtY3ZRbvOCteVep9b\n3X2xuy9uamo6qLLEzcgVjuZGKRGR6FUsMMxsulkwZM7MloRlaQeeAeab2TwzSwFXAfdGWZZYzCgo\nMEREhhVZk5SZ3Q6cBzSaWTPwZSAJ4O43A1cA/8XMckAvcJUHPdM5M/ss8BsgDqwI+zYiEzcjr6uM\nRESGFVlguPvVB9j+beDbJbatBFZGUa6hxONGXjUMEZFhaaQ3YQ1DgSEiMiwFBhCPqUlKRORAFBhA\nzAx3jZYWERmOAgNIxILJB9UsJSJSmgKD4LJaQGMxRESGocAg6MMAKKhJSkSkJAUGwVVSoCYpEZHh\nKDAoqmEUKlwQEZEjmAKDvYGRU2KIiJSkwGBvp7fGYoiIlKbAYG8fhioYIiKlKTAoGoehGoaISEkK\nDIqapPIKDBGRUhQYQDz8U1ANQ0SkNAUGwVxSoHEYIiLDUWAAiVjwx6CR3iIipSkw2NsklVMfhohI\nSQoM9jZJqYYhIlKaAoO9I73VhyEiUpoCA430FhEphwID3UBJRKQckQWGma0ws1YzW1ti+0fN7Hkz\ne8HMHjezU4u2bQrXP2tmq6Iq4wBNby4icmBR1jBuA5YOs/2PwLvd/W3A3wO3Dtp+vrsvcvfFEZVv\nj9ie6c0VGCIipSSiemN3f9TM5g6z/fGil08Cs6Iqy4HE1YchInJAR0ofxieA+4peO/Cgma02s+XD\nHWhmy81slZmtamtrO6gPj+ue3iIiBxRZDaNcZnY+QWCcU7T6HHdvMbOpwANm9oq7PzrU8e5+K2Fz\n1uLFiw/qF3/v9OYKDBGRUipawzCzU4DvA5e6e/vAendvCZ9bgXuAJVGWQ+MwREQOrGKBYWZzgLuB\na9391aL1tWZWP7AMXAQMeaXV4aKR3iIiBxZZk5SZ3Q6cBzSaWTPwZSAJ4O43A18CpgDfseAHOxde\nETUNuCdclwB+6u6/jqqcAIm4+jBERA4kyqukrj7A9k8Cnxxi/Ubg1P2PiI6mNxcRObAj5Sqpihro\nw1CTlIhIaQoMikd6V7ggIiJHMAUGEI8PBIYSQ0SkFAUGqmGIiJRDgQGEd2jV1CAiIsNQYKCR3iIi\n5VBgAImwiqFxGCIipSkw2NskpRqGiEhpCgw0vbmISDkUGGikt4hIORQY6J7eIiLlUGCg6c1FRMqh\nwADMDDPNJSUiMhwFRihuphqGiMgwFBiheEyBISIyHAVGSIEhIjI8BUYobqZxGCIiw1BghGIx00hv\nEZFhKDBCiZhpLikRkWEoMEKxmOmyWhGRYUQWGGa2wsxazWxtie1mZjea2QYze97MTi/attTM1oXb\nboiqjMV0Wa2IyPCirGHcBiwdZvsyYH74WA58F8DM4sBN4faFwNVmtjDCcgIDV0lF/SkiIkevyALD\n3R8Fdgyzy6XAjzzwJDDRzI4BlgAb3H2ju2eAO8J9IxUEhhJDRKSUSvZhzAQ2F71uDteVWj8kM1tu\nZqvMbFVbW9tBFyYeM/JqkRIRKemo7/R291vdfbG7L25qajro94mZbqAkIjKcRAU/uwWYXfR6Vrgu\nWWJ9pDTSW0RkeJWsYdwL/Gl4tdQ7gN3u/ibwDDDfzOaZWQq4Ktw3UvFYTOMwRESGEVkNw8xuB84D\nGs2sGfgyQe0Bd78ZWAlcDGwAeoCPh9tyZvZZ4DdAHFjh7i9GVc4B8ZimNxcRGU5kgeHuVx9guwOf\nKbFtJUGgjBqNwxARGV5ZTVJm9pdmNiFsPvqBma0xs4uiLtxo0khvEZHhlduH8Wfu3gFcBEwCrgW+\nFlmpRps7SXNyuq5WRKSkcgPDwueLgX8N+xRsmP2PLv97Jh/tuk3Tm4uIDKPcwFhtZvcTBMZvzKwe\nGDvDomNxUpYlp7lBRERKKrfT+xPAImCju/eY2WTCq5rGhHiKasvTm1VgiIiUUm4N4yxgnbvvMrNr\ngC8Au6Mr1ihLpKmyHL2ZXKVLIiJyxCo3ML4L9JjZqcBfA68BP4qsVKMtnqIqlqM7k690SUREjljl\nBkYuHDdxKfBtd78JqI+uWKMsniJtOXr6VcMQESml3D6MTjP7PMHltOeaWYxw1PaYkEiRyufoyeZx\nd8zGzgVgIiKHS7k1jD8B+gnGY2wlmBDwG5GVarTF0yTJ4g596vgWERlSWYERhsRPgAYz+wDQ5+5j\npw8jkSZF0BzVo45vEZEhlTs1yJXA08B/Aq4EnjKzK6Is2KiKp0h6FoAedXyLiAyp3D6MvwXOdPdW\nADNrAh4E7oyqYKMqkSahwBARGVa5fRixgbAItY/g2CNfPEnCMwB0q0lKRGRI5dYwfm1mvwFuD1//\nCaM8/Xik4mniHgRFr2oYIiJDKisw3P16M7sceGe46lZ3vye6Yo2yRJpYIaxhaCyGiMiQyr6Bkrvf\nBdwVYVkqJ57aExjqwxARGdqwgWFmncBQc34bwU3zJkRSqtFWVMNQYIiIDG3YwHD3sTP9x3DiSSw/\nEBhqkhIRGcrYudLpUMTTkOsHXDUMEZESFBgAiTSGU53QZbUiIqVEGhhmttTM1pnZBjO7YYjt15vZ\ns+FjrZnlw5szYWabzOyFcNuqKMtJPAVAQ7Kgy2pFREoo+yqpkTKzOHATcCHQDDxjZve6+0sD+7j7\nNwgnMTSzDwL/zd13FL3N+e6+Paoy7pFIAzAx5XT3KzBERIYSZQ1jCbDB3Te6ewa4g+B+GqVczd6B\ngaOruIaRVZOUiMhQogyMmcDmotfN4br9mFkNsJR9x3k48KCZrTaz5aU+xMyWm9kqM1vV1tZ2cCUN\nA2NCsqAahohICUdKp/cHgd8Pao46x90XAcuAz5jZu4Y60N1vdffF7r64qanp4D49bJKqVx+GiEhJ\nUQZGCzC76PWscN1QrmJQc5S7t4TPrcA9BE1c0QhrGHWJgq6SEhEpIcrAeAaYb2bzzCxFEAr3Dt7J\nzBqAdwO/LFpXa2b1A8vARcDayEoa1jDqkgWNwxARKSGyq6TcPWdmnwV+A8SBFe7+opldF26/Odz1\nMuB+d+8uOnwacE94b+0E8FN3/3VUZd1Tw4jlNdJbRKSEyAIDwN1XMmga9KKgGHh9G3DboHUbgVOj\nLNs+whpGbSJPjzq9RUSGdKR0elfWoD6MQmGo+RZFRMY3BQbsCYzJaafgsL27v8IFEhE58igwYE+T\n1KSq4OW23QoMEZHBFBiwt4YRPLG1o6+ChREROTIpMGDvXFLpAqDAEBEZigID9un0jseMbbsVGCIi\ngykwYE9gxPIZmurSqmGIiAxBgQF7mqTIZ5jWUMU2BYaIyH4UGBDcohUgn2H6hDRb1SQlIrIfBQZA\nLAaxBOT6mT6hSk1SIiJDUGAMiKf3NEl19uU0p5SIyCAKjAHx5J4aBsC2Dg3eExEppsAYkEhDvp9Z\nk2oA2NTefYADRETGFwXGgHga8llOmFYHwPptnRUukIjIkUWBMSCRglw/E2tSTJuQZt3WrkqXSETk\niKLAGBB2egOcMK2edds6KlwgEZEjiwJjQFjDAHjr9HrWb+sir/tiiIjsocAYEE9BPgiME6bV058r\n8MaOngoXSkTkyKHAGJBIQzYYsHfi9HoA1m1Vx7eIyAAFxoCaRujZDsD8qfWk4jHWvLGzwoUSETly\nRBoYZrbUzNaZ2QYzu2GI7eeZ2W4zezZ8fKncYw+7+unQ1QpAdSrOmfMm8fC61sg/VkTkaBFZYJhZ\nHLgJWAYsBK42s4VD7PqYuy8KH18d4bGHT91UyHRBf3A57XknTOXVbV1s2dUb6ceKiBwtoqxhLAE2\nuPtGd88AdwCXjsKxB6duWvDcHdQq3n1iEwCPvNoW6ceKiBwtogyMmcDmotfN4brBzjaz583sPjM7\naYTHYmbLzWyVma1qazuEH/e6qcFz2Cw1f2odMxqq1CwlIhKqdKf3GmCOu58C/Avwi5G+gbvf6u6L\n3X1xU1PTwZdkoIbRtQ0AM+PdJ07l9xvayeYLB/++IiJjRJSB0QLMLno9K1y3h7t3uHtXuLwSSJpZ\nYznHHnZ7AmNvjeK8E5vo6s+x+nVdLSUiEmVgPAPMN7N5ZpYCrgLuLd7BzKabmYXLS8LytJdz7GFX\nMwUstqeGAfDO4xtJxIyH16kfQ0QkssBw9xzwWeA3wMvAz939RTO7zsyuC3e7AlhrZs8BNwJXeWDI\nY6MqKwCxONQ27RMYdekEi+dO4rcvb8Nd04SIyPiWiPLNw2amlYPW3Vy0/G3g2+UeG7m6afs0SQFc\ndtpMPnfXCzyxsZ2zj2sc1eKIiBxJKt3pfWSpm7ZPDQPg0kUzaaxL8b1HN1aoUCIiRwYFRrEhahhV\nyTh/etZcHlrXxotbdleoYCIilafAKFYf1jBymX1Wf+zsuTRUJ/nn+1+tUMFERCpPgVFs2klQyEHb\ny/usbqhOct27j+N3r7SyatOOChVORKSyFBjFZpwWPG/5w36bPnb2W2iqT/P1X6/TFVMiMi4pMIpN\nmgdVE6FlzX6balIJ/vw9x/P0ph2aX0pExiUFRjGzoJYxRA0D4Koz5zBncg1//+8vkclpuhARGV8U\nGIPNPB1aX9pz971iqUSMr1yykNfauvneY7rMVkTGFwXGYDNODzq+t+zfLAXwnrdOY9nJ0/nmA6/y\n+Ibto1w4EZHKUWAMNu9ciCVh3X0ld/n6FadwXFMt1/14NRvbukaxcCIilaPAGKyqIQiNV34FJa6G\nqq9K8oOPnUkiHuMTP1zFju7MkPuJiIwlCoyhnHgx7HgNtpceqDd7cg23XHsGLbt6ufYHT7G7NzuK\nBRQRGX0KjKG89f2AwfM/G3a3M+dO5pZrz+DVbZ18bMXTdPYpNERk7FJgDGXCDFjwAXjm+9DfOeyu\n5584lZs+cjprW3bzZ7c9Q08mN0qFFBEZXQqMUt7536BvN6y+7YC7XnTSdL511SJWv76TT/5wFX3Z\nfPTlExEZZQqMUmadAceeB499E3p3HXD3D5wyg3++8lSe2NjOJ3+4SjPbisiYo8AYzoVfhd6d8Og3\nytr9stNm8X8+fApPb9rB+2/8D75y74vk8hoRLiJjgwJjOMecCqddA09+t+R0IYNdeeZsnv6fF/Cf\nz57LbY9v4uO3PcPuHnWGi8jRT4FxIBf9fXBjpbs/Df3lDdKbWJPiK5ecxNcvP4UnN7Zz8Y2P8btX\nth34QBGRI5gC40CqJ8GHvgPt6+GuT0Ch/A7tK8+czc8+fRY1qTh/dtsqvvTLtXT36yoqETk6KTDK\ncdz5sOzr8Oqv4b7PlRwBPpTT50ziV39xLp84Zx4/euJ1zv+nh/n+Yxvp0JgNETnKRBoYZrbUzNaZ\n2QYzu2GI7R81s+fN7AUze9zMTi3atilc/6yZrYqynGVZ8ik467PwzPfg998a0aGpRIwvfmAhd//X\ns5nbWMv/+tXLvPefH+EXf2ihN6NLcEXk6GBR3T3OzOLAq8CFQDPwDHC1u79UtM/ZwMvuvtPMlgFf\ncfe3h9s2AYvdvewpYRcvXuyrVkWYLYUC3P1JWHsXXPAlOOe/B/fQGKE/vLGTz9/9Aq9s7aQ2FeeK\nM2bxV+89gUm1qQgKLSJSmpmtdvfF5eybiLAcS4AN7r4xLNQdwKXAnsBw98eL9n8SmBVheQ5dLAaX\n3QoY/ParsHUtXPIvkK4b0ducFjZTPbWxnTtXN/PTp9/g4Vfb+ML7F3LWcVOoS0f5tYiIHJwof5lm\nApuLXjcDbx9m/08AxXOKO/CgmeWBW9z91qEOMrPlwHKAOXPmHFKByxJPwOXfh+knB6HR+jJ8+Jbg\nEtyRvE3MOPv4Rs4+vpFrznoLn/7X1XzqR6tIxIwz507mg6fO4OK3TWdijWodInJkiLJJ6gpgqbt/\nMnx9LfB2d//sEPueD3wHOMfd28N1M929xcymAg8Af+7ujw73mZE3SQ322u+Cy2172uHsP4fzboBk\n9UG9VV82z5rXd/Lo+u3c/9JWNrZ1k4wb7z6hiUsWzeS9C6ZSk1LNQ0QOr5E0SUUZGGcR9Em8L3z9\neQB3/8dB+50C3AMsc/ch5xM3s68AXe7+T8N95qgHBkDPDnjgi/CHH8PkY+GDNwb30zgE7s6LWzq4\n97kt3PvsFrZ29FGTivO+k6Zz7Vlv4fQ5kw5T4UVkvDtSAiNB0Ol9AdBC0On9EXd/sWifOcDvgD8t\n7s8ws1og5u6d4fIDwFfd/dfDfWZFAmPAxofh3/4Sdm4KRoef+zcwed4hv22h4Dy9aQe/fHYL//7c\nFjr7c5w6eyKLZjUwa1IN7104jXmNtYf8OSIyPh0RgREW5GLgW0AcWOHu/2Bm1wG4+81m9n3gcuD1\n8JCcuy82s2MJah0Q9LP81N3/4UCfV9HAAMj0wMP/CE9+B7wAiz4C7/ofMOkth+Xtu/tz3L2mmZ88\n9QZv7u7bc9Om97x1KqfPmch7F07jmIagSayhOnlYPlNExrYjJjBGW8UDY0DHFnj828GYjUIOTlgG\nb18O8959UJfhltKyq5efPbOZO1dtZsvuvj3rU4kYl58+iw+eegynzppIra66EpESFBhHit3N8MwP\ngntq9O6ApgXBAMC3XRHcO/ww2tGd4ZfPttCbzfNGew93/6GFTC6YKXf25GpOnFbPnMm1NFQnuXrJ\nbBrr0piBHcYAE5GjjwLjSJPtCwb7PXUzbH0e4mmYfyGcdFnwfJjDA4Lmqydea+eVrR28srWTV7d1\n0rKzl55snqpEHMeZUJXkPW+dyodPn8WJ0+qpScdJxjVbjMh4osA4UrlDy2p44U548W7o2gaxJMw9\nB+ZfBMe/FxrnH9Zmq8H+uL2bWx55jZpUgtbOPn73Sis9RdOTNNalWDijgXOPb2TRnIls6+jjrdMn\ncPzUkQ1OFJGjgwLjaFDIQ/MzsG4lrLsPtodXFDfMhuMvgOMugNlvh/ppkRajsy/L7ze007yzh55M\nnpadvax6fQevtXXvs9/8qXVcsGAaJ8+cwKSaFCdOr6exLk02XyCTK6ifROQopcA4Gu16Azb8FjY8\nCBsfgUxnsH7a22Deu6DpBGg8ARpPhNopkRdny65eXtrSwdQJada8vpP71m5l9es7yRX2/n1JJWJk\n8wXcYdakat5x7BSmTUgzY2I1i2ZP5MRp9STUxCVyRFNgHO3yWWhZA288EdQ+3nwOcr17t085Huae\nCzNOg4ZZQa2kYSakoh2P0ZfNs7Gtm509GV7a0sH27n7SiTipuLG2pYOn/thOR1+OfBgqtak4p82Z\nRCZfYGp9mqb6NImYcdZxUzAz3jK5BoBcwTmuqY54TB3wIqNNgTHWFAqwezNsXw+tL8LrjweP/o59\n95t6Esw+EyYfBxPnBDd/mjwPJswKJk4cBe7O5h29/GHzTp7+4w7+8MYuatNxWnb20tGXIxM2YQ1W\nk4pz8ow85LAIAAAOWElEQVQGptSlmNtYy5zJNVQlYyRiMTr7ciyZN4kZE6vpzxZoqE6yoyfDlNoU\n+YLjoM56kYOkwBgP8jno3BJcuru7JRhhvunRYAbd3h377pusgZopkEjDpHlBDWVKGCp1U4Nb0NZO\nDSZWjFhPJsfzzbtJxIyNbd2YBRMxPrd5F2u3dLCrJ8Pr7T37NH0Nlowb2bwze3I1u7qzOHDBgqmc\nO7+J3b1Z5jXWMGdyLcm4UZtOMKU2hZkx8HddlxKL7KXAGO96dwZB0rsTdmyEtleD5Wx38Lp9Y7C8\nDwtCpW5a0NFeV/yYCvXT975O10d6JVdfNs+O7gx92Ty5gpOKx3jw5W30ZvJUp+K0dfYzuTbF03/c\nQWNdGoD7X9rKzp6h72I4oSrBxJoU27v6gaAD//ip9UGwTKmlLh0nk3NSCWPx3MnEzfZpHqtKxgHI\n5QvEY6bAkTFFgSHDc4fOrcGI9K6tweW9Xa3Buq7WcF1rsD6f2f/4RHUQIrEExJNQPTlo/qqZVLQ8\ned/lVC0kqoJaTqIqGItyGJvJcvkCr7V1M7k2xYbWLlo7+8jlnY6+LBvbuunoyzK5NoU7bGjtYn1r\nJ9s6+g/4vomYsXDGBHb2ZNiyq49JNUnOOb6R+dPqefnNDo6fWse2jn7SiRgXLZxGR1+OybUpTpox\nQVeOyVFBgSGHh3tQMxkcIgPB4vkgUHp2Bvv17ghm780f+IcYgFQdVE0MgqZqIsTiYLGgBlPTGIRN\nqjbYL1VbtFwTBE88DJ9EKgyh1N5QKqMW0JvJ88aOHvqyeZLxGLt7s6x+fQeJeGxPx31nX47nNu+i\nqT7N7MnVtOzs5bH122nvzjBtQpptHf3UpxP0D+qbSSVizGioAiBmRnUqTm0qQU82R3tXhkyuwIyJ\n1cyaVM0psyYysSaY++uYhiqad/aSjBt16SSOE7PgHimNdcG9UVTDkcNJgSGVlenZGyC9O4MQyfZA\nrg9y/cFzti/otO/dFezXtzuYsLGQD9b3tAfH+v4d5GWJp8JACR/xVBBwyRqobQreN54K7l8yED7x\n5BDLqTCI9i4X4im683Hqa2rozsdJx52uXIzXdhsTq+NszyZ5ojnPtl4HnELB6coaHVkjlUozqa6a\nZDzGm7t7eb29hz9uH9w8OLSqZIxs3mmoTlJflWBHV4bjp9WxqyeoPc2dUkvBnV09GU6cPoGZk4KA\n292bYcExE1gybzItO3vJFZxJNSkm1SRpqEkysTpFKhEjkyvQk8lRX5XUFWvjiAJDxgb3IFwy3YMe\nXUHNJtcfPPJhCOUye0Mp3793+8BriwfHdm8PmtPy/UFwDeybz4bLmeB5qOa4w8FiwQh/M8BwM5xg\nuYARi8XwWBy3BG5xChanL29kPEEhlqTf42Q9DokUnVkjnkiSzeYo5PqJeQGPJ+nIGP2eIGcJiCXp\nzsUI4suKHntfJ+IxsgUn53H6SUIiRSqRIJ2Mk0qmqE4ak6ybVCJGKpmkN+e0d+fozDg1VSnqq1Nk\n8kYikWBibZrWrhwLZkwklUrSm3XiiQSpRILWrhxNE6qZMamWeCJJpuBkCzFq0klyxIjF4sTjifDP\nKKxx2kDTpRXVHC3YPtAsGkuGz4lgvReCvz/43uU9r8N1A9v2fjFF7xe+j8X3lmPgNQT/wcHD/0SE\nn4/v/5lme2vCsVhwxaPng/8YxVN7m2UH/q7n+oLPiqf33V6KF53PQV60cqTc01vk0JgFNYBkNdQ2\njv7nu+8NkXy2KIgyQZgMLMfiwbb+zuCHpr8D+nYFV7INKGTDY3LBcyG758fFPHiAExv4x+/5YKbj\nfA4KOdKFbFCGQnh88Xvle4IyxGuD53yWQj5DIdtFrJDDChny2QzZXJ54DAzHvYAXHPdw2T34bfM8\nsUKGhGchR/AIhwD1kqbgEMOJUyBuBeIUoA/YNcSf35v7r5o16HUqfACMywn5E1WA7TvOqlgsGQQH\nhH8vBj0I/8NfOxWuXx99cSP/BJGjlVnYP3L03Vc9Fj4GJBjhP/bCwP/APQgpM6oTadydvmyBeCK2\nt9nKPfgfs+fp6c+wo7OPxtoED73yJuk4TKmJ09efpacvw6xJVbyxvZPnN+8gk80xe2KadNxp6+ih\nPhWnp7+fzp5+0nF4c1cP5nmSMaM+Hac6FefN3b3ELZjSpnV3Dwly1Cchl82QIE/ScsRwChhNdWla\nu7IUHArsX8MqhM+YgQdrExRIkCNpeRqqYiRwzPNMrI6TNKcvk6G+Ksm2TJqadBLPZ+nv62ViGo5p\nqCaHkU7Eyead7d1ZEgZVsRxVZEjGoKYqTdOEarZ2ZqiJ5env7SJu0DR5Eh35BDv7Y3T09jM5DcdO\nSpLP9pPP9hMzo74mRUNNmnhRzSvnEIvFiaVHZ643BYaI7K+4KaSoqcPCDvx9mIX7JKhJpKmprQdg\n2ZlD30p4/gnBbTgP1e7eLL2ZPNMbqvZchl1wp1CA2nScKXVpdnZneHR9GzWpBHOn1PBaWxf9ueAC\nhXQyzs7uDO1d/Syc0cCE6gRtnf109GbZ0Z2lZVcPRhCKq3d0ky84jXVptnb00dSYZntXMNPBMbOr\neGJXLy8076YqGaezL0syHmP+1Dry7mRyBfpzBfqzBdpa+skXfCCjSCdiFNzJbgpqCjGDaROq2NbR\nR6mhSLWpOLXpBJ19OXqzeaqTcU6eOYGfn+WRXxChwBCRo1JDdXLPnSUn1w5dC5xUm+LSRTP3vJ4/\nrT7ycuXyBWzQWJ4BO7szvLqtk1NmTaQ/l6c2naC7P8eG1i6mN1QxfUIVifCCiFe3dVGbCmpWubzz\nWlsXm3f0srs3S3d/jvqqBBNrkuzoztKTyY3K1XPq9BYRGcdG0umtCXhERKQsCgwRESlLpIFhZkvN\nbJ2ZbTCzG4bYbmZ2Y7j9eTM7vdxjRURkdEUWGGYWB24ClgELgavNbOGg3ZYB88PHcuC7IzhWRERG\nUZQ1jCXABnff6O4Z4A7g0kH7XAr8yANPAhPN7JgyjxURkVEUZWDMBDYXvW4O15WzTznHAmBmy81s\nlZmtamtrO+RCi4jI0I76Tm93v9XdF7v74qampkoXR0RkzIpy4F4LMLvo9axwXTn7JMs4VkRERlGU\ngfEMMN/M5hH82F8FfGTQPvcCnzWzO4C3A7vd/U0zayvj2P2sXr16u5m9fpDlbQS2H+SxRyud8/ig\ncx4fDvac31LujpEFhrvnzOyzwG+AOLDC3V80s+vC7TcDK4GLgQ1AD/Dx4Y4t4zMPuk3KzFaVO9px\nrNA5jw865/FhNM450rmk3H0lQSgUr7u5aNmBz5R7rIiIVM5R3+ktIiKjQ4Gx162VLkAF6JzHB53z\n+BD5OY+p2WpFRCQ6qmGIiEhZFBgiIlKWcR8Y42VWXDPbZGYvmNmzZrYqXDfZzB4ws/Xh89D31DyK\nmNkKM2s1s7VF60qep5l9Pvzu15nZ+ypT6kNT4py/YmYt4ff9rJldXLTtqD5nM5ttZg+Z2Utm9qKZ\n/WW4fqx/z6XOe/S+a3cftw+CMR6vAccCKeA5YGGlyxXRuW4CGget+zpwQ7h8A/B/Kl3Ow3Ce7wJO\nB9Ye6DwJZkJ+DkgD88K/C/FKn8NhOuevAH8zxL5H/TkDxwCnh8v1wKvheY3177nUeY/adz3eaxjj\nfVbcS4Efhss/BD5UwbIcFu7+KLBj0OpS53kpcIe797v7HwkGkC4ZlYIeRiXOuZSj/pzd/U13XxMu\ndwIvE0xOOta/51LnXcphP+/xHhhlz4o7BjjwoJmtNrPl4bpp7v5muLwVmFaZokWu1HmO9e//z8Mb\nk60oap4ZU+dsZnOB04CnGEff86DzhlH6rsd7YIwn57j7IoKbUn3GzN5VvNGDOuyYv8Z6vJwnwc3I\njgUWAW8C/1zZ4hx+ZlYH3AX8lbt3FG8by9/zEOc9at/1eA+McmbUHRPcvSV8bgXuIaiabgtvWEX4\n3Fq5Ekaq1HmO2e/f3be5e97dC8D32NsUMSbO2cySBD+aP3H3u8PVY/57Huq8R/O7Hu+BsWdGXTNL\nEcyKe2+Fy3TYmVmtmdUPLAMXAWsJzvVj4W4fA35ZmRJGrtR53gtcZWbpcGbk+cDTFSjfYTfwwxm6\njOD7hjFwzmZmwA+Al939m0WbxvT3XOq8R/W7rnTPf6UfBLPlvkpwBcHfVro8EZ3jsQRXSzwHvDhw\nnsAU4LfAeuBBYHKly3oYzvV2gmp5lqDN9hPDnSfwt+F3vw5YVunyH8Zz/lfgBeD58IfjmLFyzsA5\nBM1NzwPPho+Lx8H3XOq8R+271tQgIiJSlvHeJCUiImVSYIiISFkUGCIiUhYFhoiIlEWBISIiZVFg\niBwBzOw8M/v3SpdDZDgKDBERKYsCQ2QEzOwaM3s6vO/ALWYWN7MuM/u/4T0KfmtmTeG+i8zsyXBS\nuHsGJoUzs+PN7EEze87M1pjZceHb15nZnWb2ipn9JBzZK3LEUGCIlMnMFgB/ArzTg4kc88BHgVpg\nlbufBDwCfDk85EfA59z9FIKRuAPrfwLc5O6nAmcTjNKGYPbRvyK4j8GxwDsjPymREUhUugAiR5EL\ngDOAZ8L//FcTTHBXAH4W7vNj4G4zawAmuvsj4fofAv8vnNNrprvfA+DufQDh+z3t7s3h62eBucB/\nRH9aIuVRYIiUz4Afuvvn91lp9sVB+x3sfDv9Rct59O9TjjBqkhIp32+BK8xsKuy5h/RbCP4dXRHu\n8xHgP9x9N7DTzM4N118LPOLBndKazexD4XukzaxmVM9C5CDpfzAiZXL3l8zsC8D9ZhYjmB32M0A3\nsCTc1krQzwHBFNs3h4GwEfh4uP5a4BYz+2r4Hv9pFE9D5KBptlqRQ2RmXe5eV+lyiERNTVIiIlIW\n1TBERKQsqmGIiEhZFBgiIlIWBYaIiJRFgSEiImVRYIiISFn+P6HuwPur8911AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f08782622b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1671)  # for reproducibility\n",
    "\n",
    "# network and training\n",
    "NB_EPOCH = 250\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10   # number of outputs = number of digits\n",
    "OPTIMIZER = SGD() # optimizer, explained later in this chapter\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
    "DROPOUT = 0.3\n",
    "\n",
    "# data: shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
    "RESHAPED = 784\n",
    "#\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# normalize \n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "# M_HIDDEN hidden layers\n",
    "# 10 outputs\n",
    "# final stage is softmax\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(DROPOUT))\n",
    "model.add(Dense(N_HIDDEN))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(DROPOUT))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=OPTIMIZER,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "                    verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
